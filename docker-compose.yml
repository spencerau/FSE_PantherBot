#version: "3.8"
services:
  slack-bot:
    build: .
    command: python src/slack/bot.py
    volumes:
      - ./src:/app/src
      - ./configs:/app/configs
      - ./data:/app/data
    environment:
      - QDRANT_HOST=qdrant
      - OLLAMA_HOST=host.docker.internal
      - RERANK_DISABLED=true
      - PYTHONPATH=/app/src
    env_file:
      - ./src/slack/.env
      - ./src/memory/.env
    depends_on:
      - qdrant
      - postgres
    restart: unless-stopped

  app:
    build: .
    ports:
      - "3000:8501"
    volumes:
      - ./src:/app/src
      - ./configs:/app/configs
      - ./data:/app/data
    environment:
      - QDRANT_HOST=qdrant
      - OLLAMA_HOST=host.docker.internal
      - PYTHONPATH=/app/src
    depends_on:
      - qdrant
      - tika

  streamlit:
    build: .
    command: streamlit run src/streamlit_app.py --server.port=8501 --server.address=0.0.0.0
    ports:
      - "8501:8501"
    volumes:
      - ./src:/app/src
      - ./configs:/app/configs
      - ./data:/app/data
    environment:
      - QDRANT_HOST=qdrant
      - OLLAMA_HOST=host.docker.internal
      - PYTHONPATH=/app/src
    depends_on:
      - qdrant
      - tika

  qdrant:
    image: qdrant/qdrant
    volumes:
      - ./qdrant_data:/qdrant/storage
    ports:
      - "6333:6333"

  postgres:
    image: postgres:15
    volumes:
      - ./postgres_data:/var/lib/postgresql/data
    env_file:
      - ./src/memory/.env
    ports:
      - "5432:5432"
    restart: unless-stopped

  memory-compressor:
    build: .
    command: bash scripts/memory_compression.sh
    volumes:
      - ./src:/app/src
      - ./configs:/app/configs
      - ./scripts:/app/scripts
    environment:
      - OLLAMA_HOST=host.docker.internal
      - PYTHONPATH=/app/src
    env_file:
      - ./src/memory/.env
    depends_on:
      - postgres
    restart: unless-stopped

  # ollama:
  #   image: ollama/ollama
  #   volumes:
  #     - ./ollama_data:/root/.ollama
  #   ports:
  #     - "11434:11434"
  #   environment:
  #     - OLLAMA_NUM_PARALLEL=2
  #     - OLLAMA_MAX_LOADED_MODELS=2
  #     - OLLAMA_FLASH_ATTENTION=1
  #     - OLLAMA_KV_CACHE_TYPE=q8_0
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 8G

  tika:
    image: apache/tika:latest
    ports:
      - "9998:9998"